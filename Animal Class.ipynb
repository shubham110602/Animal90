{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3952946,"sourceType":"datasetVersion","datasetId":1554380},{"sourceId":7832377,"sourceType":"datasetVersion","datasetId":4590437},{"sourceId":8018545,"sourceType":"datasetVersion","datasetId":4724635},{"sourceId":8079747,"sourceType":"datasetVersion","datasetId":4768676}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torchvision.models as models\nfrom torchvision import transforms\nimport torchvision.datasets as datasets\nfrom torch.utils.data import DataLoader, random_split\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch import nn\nimport pandas as pd\nimport cv2\nimport imghdr\nfrom sklearn.metrics import classification_report\nfrom matplotlib import pyplot as plt\nfrom tqdm import tqdm\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/animal-image-dataset-90-different-animals/animals/animals'):\n    for filename in filenames:\n        file_path = os.path.join(dirname, filename)\n        try:\n            img = cv2.imread(file_path)\n            tip = imghdr.what(file_path)\n#             print(tip)\n            if tip != 'jpeg':\n                print('Image not in ext list {}'.format(file_path))\n                os.remove(file_path)\n        except Exception as e:\n            print('Issue with image {}'.format(file_path))\n        ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-14T09:41:55.361585Z","iopub.execute_input":"2024-04-14T09:41:55.362037Z","iopub.status.idle":"2024-04-14T09:42:57.393861Z","shell.execute_reply.started":"2024-04-14T09:41:55.362006Z","shell.execute_reply":"2024-04-14T09:42:57.393038Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# CUDA_LAUNCH_BLOCKING=1\n# TORCH_USE_CUDA_DSA","metadata":{"execution":{"iopub.status.busy":"2024-04-14T09:42:57.395423Z","iopub.execute_input":"2024-04-14T09:42:57.395708Z","iopub.status.idle":"2024-04-14T09:42:57.399916Z","shell.execute_reply.started":"2024-04-14T09:42:57.395684Z","shell.execute_reply":"2024-04-14T09:42:57.398861Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"data_dir = '/kaggle/input/animal-image-dataset-90-different-animals/animals/animals'\n\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.Grayscale(3),  # Convert to RGB (3 channels)\n    transforms.ToTensor(),\n#     transforms.Normalize(mean=[0.5], std=[0.5]),\n])\n\ndataset = datasets.ImageFolder(root = data_dir, transform=transform)\nclass_names = dataset.classes\nprint(class_names)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T09:42:57.401064Z","iopub.execute_input":"2024-04-14T09:42:57.401387Z","iopub.status.idle":"2024-04-14T09:42:57.489870Z","shell.execute_reply.started":"2024-04-14T09:42:57.401335Z","shell.execute_reply":"2024-04-14T09:42:57.488883Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"['antelope', 'badger', 'bat', 'bear', 'bee', 'beetle', 'bison', 'boar', 'butterfly', 'cat', 'caterpillar', 'chimpanzee', 'cockroach', 'cow', 'coyote', 'crab', 'crow', 'deer', 'dog', 'dolphin', 'donkey', 'dragonfly', 'duck', 'eagle', 'elephant', 'flamingo', 'fly', 'fox', 'goat', 'goldfish', 'goose', 'gorilla', 'grasshopper', 'hamster', 'hare', 'hedgehog', 'hippopotamus', 'hornbill', 'horse', 'hummingbird', 'hyena', 'jellyfish', 'kangaroo', 'koala', 'ladybugs', 'leopard', 'lion', 'lizard', 'lobster', 'mosquito', 'moth', 'mouse', 'octopus', 'okapi', 'orangutan', 'otter', 'owl', 'ox', 'oyster', 'panda', 'parrot', 'pelecaniformes', 'penguin', 'pig', 'pigeon', 'porcupine', 'possum', 'raccoon', 'rat', 'reindeer', 'rhinoceros', 'sandpiper', 'seahorse', 'seal', 'shark', 'sheep', 'snake', 'sparrow', 'squid', 'squirrel', 'starfish', 'swan', 'tiger', 'turkey', 'turtle', 'whale', 'wolf', 'wombat', 'woodpecker', 'zebra']\n","output_type":"stream"}]},{"cell_type":"code","source":"loader = DataLoader(dataset, batch_size=64, shuffle=True)\n\nmean_sum = torch.zeros(3)\nstd_sum = torch.zeros(3)\ncount = 0\n\n# Calculate mean and standard deviation for each channel\nfor images, _ in loader:\n    batch_size = images.size(0)\n    count += batch_size\n    mean_sum += images.mean(dim=[0, 2, 3]) * batch_size\n    std_sum += images.std(dim=[0, 2, 3]) * batch_size\n\n# Calculate the overall mean and standard deviation\nmean = mean_sum / count\nstd = std_sum / count\n\nprint(f\"Estimated Mean: {mean}\")\nprint(f\"Estimated Std: {std}\")\n    \n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T09:42:57.492632Z","iopub.execute_input":"2024-04-14T09:42:57.493299Z","iopub.status.idle":"2024-04-14T09:44:04.894785Z","shell.execute_reply.started":"2024-04-14T09:42:57.493262Z","shell.execute_reply":"2024-04-14T09:44:04.893795Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Estimated Mean: tensor([0.4962, 0.4962, 0.4962])\nEstimated Std: tensor([0.2631, 0.2631, 0.2631])\n","output_type":"stream"}]},{"cell_type":"code","source":"normalize_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.Grayscale(3),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=mean, std=std)\n])\n\ndataset = datasets.ImageFolder(root=data_dir, transform=normalize_transform)\n# for image, labels in dataloader:\n#     print(labels)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T09:44:04.896018Z","iopub.execute_input":"2024-04-14T09:44:04.896391Z","iopub.status.idle":"2024-04-14T09:44:04.979151Z","shell.execute_reply.started":"2024-04-14T09:44:04.896333Z","shell.execute_reply":"2024-04-14T09:44:04.978378Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train_size = int(len(dataset)*.7)\n# valid_size = int(len(dataset)*.2)\ntest_size = int(len(dataset) - train_size)\n\ntrain, test = random_split(dataset, [train_size, test_size])\n\nbatch_size = 16\ntrain_dataloader = DataLoader(train, batch_size=batch_size, shuffle=True)\n# valid_dataloader = DataLoader(valid, batch_size=batch_size, shuffle=False)\ntest_dataloader = DataLoader(test, batch_size=batch_size, shuffle=False)\n# transform = transforms.Compose([\n#     transforms.Resize((224, 224)),\n#     transforms.Grayscale(3),\n#     transforms.ToTensor(),\n#     transforms.Normalize(mean=[0.5], std=[0.5]),\n# ])\n\n# mnist_train_dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n# mnist_test_dataset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n\n# train_loader = DataLoader(mnist_train_dataset, batch_size=32, shuffle=True)\n# test_loader = DataLoader(mnist_test_dataset, batch_size=32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T09:44:04.980268Z","iopub.execute_input":"2024-04-14T09:44:04.980610Z","iopub.status.idle":"2024-04-14T09:44:04.987925Z","shell.execute_reply.started":"2024-04-14T09:44:04.980583Z","shell.execute_reply":"2024-04-14T09:44:04.986912Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"class CNNModel(nn.Module):\n    def __init__(self, num_classes = 90):\n        super(CNNModel, self).__init__()\n        \n        self.conv1 = nn.Conv2d(3, 64, kernel_size = 3, stride = 1)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.conv2 = nn.Conv2d(64, 128, kernel_size = 3, stride =1 )\n        self.bn2 = nn.BatchNorm2d(128)\n        self.conv3 = nn.Conv2d(128, 256, kernel_size = 3, stride = 1)\n        self.bn3 = nn.BatchNorm2d(256)\n        \n        self.relu = nn.ReLU()\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n        \n        self.fc1 = nn.Linear(256*26*26, 512)\n        self.bn4 = nn.BatchNorm1d(512)\n        self.fc2 = nn.Linear(512, num_classes)\n        self.bn5 = nn.BatchNorm1d(num_classes)\n        \n        self.softmax = nn.Softmax(dim=1)\n    \n    def forward(self, x):\n#         print(x.size())\n        x = self.pool(self.relu(self.bn1(self.conv1(x))))\n#         print(x.size())\n        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n#         print(x.size())\n        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n#         print(x.size())\n        x = x.view(-1, 256*26*26)\n#         print(x.size())\n        x = self.relu(self.bn4(self.fc1(x)))\n#         print(x.size())\n        x = self.bn5(self.fc2(x))\n#         x = F.log_softmax(x, 1)\n#         print(x.size())\n        \n        return x\n\nmodel = CNNModel().to('cuda')\ncriterion = nn.CrossEntropyLoss()\noptimiser = optim.Adam(model.parameters(), lr=1e-5, weight_decay=1e-5)\n\n# alexnet_model = models.alexnet(pretrained=True)\n\n# num_features = alexnet_model.classifier[6].in_features\n# alexnet_model.classifier[6] = nn.Linear(num_features, 90)\n# alexnet_model = alexnet_model.to(\"cuda\")\n# alexnet_model.train()\n\n# num_ftrs = alexnet_model.fc.in_features\n# alexnet_model.fc = torch.nn.Linear(num_ftrs, 90)\n\n# alexnet_model = models.vgg16(pretrained=True)\n\n# # Modify the classifier to match your number of classes\n# num_features = alexnet_model.classifier[6].in_features\n# alexnet_model.classifier[6] = nn.Linear(num_features, 90)\n# alexnet_model = alexnet_model.to(\"cuda\")\n# alexnet_model.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-14T09:44:04.989316Z","iopub.execute_input":"2024-04-14T09:44:04.989700Z","iopub.status.idle":"2024-04-14T09:44:06.033514Z","shell.execute_reply.started":"2024-04-14T09:44:04.989666Z","shell.execute_reply":"2024-04-14T09:44:06.032495Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# for param in alexnet_model.parameters():\n#     param.requires_grad = False\n    \n# for param in alexnet_model.classifier.parameters():\n#     param.requires_grad = True","metadata":{"execution":{"iopub.status.busy":"2024-04-14T09:44:06.034823Z","iopub.execute_input":"2024-04-14T09:44:06.035105Z","iopub.status.idle":"2024-04-14T09:44:06.039312Z","shell.execute_reply.started":"2024-04-14T09:44:06.035080Z","shell.execute_reply":"2024-04-14T09:44:06.038394Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# criterion = nn.CrossEntropyLoss()\n# optimiser = optim.Adam(alexnet_model.parameters(), lr=1e-5, weight_decay=1e-5)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T09:44:06.040703Z","iopub.execute_input":"2024-04-14T09:44:06.041013Z","iopub.status.idle":"2024-04-14T09:44:06.047180Z","shell.execute_reply.started":"2024-04-14T09:44:06.040983Z","shell.execute_reply":"2024-04-14T09:44:06.046395Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"num_epoch = 10\n# for epoch in range(num_epoch):\n#     alexnet_model.train()\n#     train_loss = 0.0\n#     for images, labels in train_dataloader:\n#         images, labels = images.to('cuda'), labels.to('cuda')\n#         optimiser.zero_grad()\n#         output = alexnet_model(images)\n# #         output = output.float()\n# #         labels = labels.long()\n# #         print(output)\n#         loss = criterion(output, labels)\n#         loss.backward()\n#         optimiser.step()\n#         total_loss = loss.item()\n        \n#     avg_loss = total_loss/len(train_dataloader)\n#     print(f'Training Epoch [{epoch+1}/{num_epoch}], Loss: {avg_loss}')\n    \n\n\nfor epoch in range(num_epoch):\n    for inputs, labels in train_dataloader:\n        optimiser.zero_grad()\n        inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimiser.step()\n        \n    print(f\"Epoch [{epoch+1}/{num_epoch}], Loss: {loss.item()}\")\n    \n# torch.save(model.state_dict(), 'custom_cnn_model_gpu.pth')","metadata":{"execution":{"iopub.status.busy":"2024-04-14T09:44:06.050934Z","iopub.execute_input":"2024-04-14T09:44:06.051253Z","iopub.status.idle":"2024-04-14T09:52:10.036531Z","shell.execute_reply.started":"2024-04-14T09:44:06.051228Z","shell.execute_reply":"2024-04-14T09:52:10.035126Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Epoch [1/10], Loss: 3.556795358657837\nEpoch [2/10], Loss: 3.6404407024383545\nEpoch [3/10], Loss: 3.5529167652130127\nEpoch [4/10], Loss: 3.5296106338500977\nEpoch [5/10], Loss: 3.977418899536133\nEpoch [6/10], Loss: 3.4618682861328125\nEpoch [7/10], Loss: 3.522200584411621\nEpoch [8/10], Loss: 3.3904449939727783\nEpoch [9/10], Loss: 3.4630165100097656\nEpoch [10/10], Loss: 3.5220754146575928\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Epoch [1/10], Loss: 0.6496276259422302\nEpoch [2/10], Loss: 0.025630353018641472\nEpoch [3/10], Loss: 0.035333409905433655\nEpoch [4/10], Loss: 0.06272778660058975\nEpoch [5/10], Loss: 0.014833853580057621\nEpoch [6/10], Loss: 0.0015034597599878907\nEpoch [7/10], Loss: 0.0040255882777273655\nEpoch [8/10], Loss: 0.00011664794146781787\nEpoch [9/10], Loss: 0.0008121779537759721\nEpoch [10/10], Loss: 0.03196653351187706\n\n\nEpoch [1/10], Loss: 8.662488653499167e-06\nEpoch [2/10], Loss: 6.5564759097469505e-06\nEpoch [3/10], Loss: 0.00017892976757138968\nEpoch [4/10], Loss: 1.8635873857419938e-05\nEpoch [5/10], Loss: 1.839747892518062e-05\nEpoch [6/10], Loss: 7.362770702457055e-05\nEpoch [7/10], Loss: 0.00014585816825274378\nEpoch [8/10], Loss: 0.007957431487739086\nEpoch [9/10], Loss: 0.0009501574095338583\nEpoch [10/10], Loss: 0.0009352660272270441","metadata":{}},{"cell_type":"markdown","source":"For AlexNet\nEpoch [1/5], Loss: 0.0\nEpoch [2/5], Loss: 0.0\nEpoch [3/5], Loss: 0.0\nEpoch [4/5], Loss: 0.0\nEpoch [5/5], Loss: 0.0\n\nFor ResNet\nEpoch [1/5], Loss: 2.1291191577911377\nEpoch [2/5], Loss: 2.1237082481384277\nEpoch [3/5], Loss: 2.1333234310150146\nEpoch [4/5], Loss: 2.130035161972046\nEpoch [5/5], Loss: 2.127274751663208","metadata":{}},{"cell_type":"code","source":"# alexnet_model.eval()\nfor epoch in range(num_epoch):\n    \n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, labels in tqdm(test_dataloader):\n    #         print(images)\n    #         fig, axes = plt.subplots(1,1)\n    #         axes.imshow(images)\n    #         plt.show()\n    #         plt.imshow(images)\n    #         t_i = normalize_transform(images)\n    #         actual_batch_size = images.size(0)\n    #         plt.figure(figsize=(15, 15))  # Adjust figure size as needed\n    #         for i in range(actual_batch_size):\n    #             plt.subplot(4, 8, i + 1)  # Assuming 32 images will be displayed in a 4x8 grid\n    # #             plt.imshow(transforms.ToPILImage()(images[i]))\n    #             plt.imshow((images[i].permute(1, 2, 0)))# Convert tensor back to PIL Image for plotting\n    #             plt.title(f'Label: {class_names[labels[i]]}')\n    #             plt.axis('off')\n    #         plt.show()\n            images, labels = images.to('cuda'), labels.to('cuda')\n\n            optimiser.zero_grad()\n            output = model(images)\n    #         i, predicted = torch.max(output.data, 1)\n            predicted = torch.argmax(torch.softmax(output, dim=1), dim=1)\n\n    #         print(labels)\n    #         for i in range(actual_batch_size):\n    #             print(class_names[predicted[i]])\n    #         print(predicted)\n            correct += predicted.eq(labels).sum().item()\n            total += labels.size(0)\n\n        accuracy = correct/total\n        print(f\"Epoch {epoch + 1}/{num_epoch}, Validation Accuracy: {accuracy * 100:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2024-04-14T09:58:30.189206Z","iopub.execute_input":"2024-04-14T09:58:30.189929Z","iopub.status.idle":"2024-04-14T10:02:23.554144Z","shell.execute_reply.started":"2024-04-14T09:58:30.189891Z","shell.execute_reply":"2024-04-14T10:02:23.553144Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"100%|██████████| 102/102 [00:23<00:00,  4.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10, Validation Accuracy: 30.35%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 102/102 [00:23<00:00,  4.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/10, Validation Accuracy: 30.35%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 102/102 [00:23<00:00,  4.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/10, Validation Accuracy: 30.35%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 102/102 [00:23<00:00,  4.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/10, Validation Accuracy: 30.35%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 102/102 [00:23<00:00,  4.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/10, Validation Accuracy: 30.35%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 102/102 [00:23<00:00,  4.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6/10, Validation Accuracy: 30.35%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 102/102 [00:23<00:00,  4.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7/10, Validation Accuracy: 30.35%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 102/102 [00:23<00:00,  4.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8/10, Validation Accuracy: 30.35%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 102/102 [00:23<00:00,  4.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9/10, Validation Accuracy: 30.35%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 102/102 [00:23<00:00,  4.40it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 10/10, Validation Accuracy: 30.35%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Epoch 1/10, Validation Accuracy: 78.78%\nEpoch 2/10, Validation Accuracy: 78.78%\nEpoch 3/10, Validation Accuracy: 78.78%\nEpoch 4/10, Validation Accuracy: 78.78%\nEpoch 5/10, Validation Accuracy: 78.78%\nEpoch 6/10, Validation Accuracy: 78.78%\nEpoch 7/10, Validation Accuracy: 78.78%\nEpoch 8/10, Validation Accuracy: 78.78%\nEpoch 9/10, Validation Accuracy: 78.78%\nEpoch 10/10, Validation Accuracy: 78.78%\n\n\n\n\nEpoch 1/10, Validation Accuracy: 80.38%\nEpoch 2/10, Validation Accuracy: 80.38%\nEpoch 3/10, Validation Accuracy: 80.38%\nEpoch 4/10, Validation Accuracy: 80.38%\nEpoch 5/10, Validation Accuracy: 80.38%\nEpoch 6/10, Validation Accuracy: 80.38%\nEpoch 7/10, Validation Accuracy: 80.38%\nEpoch 8/10, Validation Accuracy: 80.38%\nEpoch 9/10, Validation Accuracy: 80.38%\nEpoch 10/10, Validation Accuracy: 80.38%","metadata":{}},{"cell_type":"markdown","source":"For AlexNet\nEpoch 1/5, Validation Accuracy: 100.00%\nEpoch 2/5, Validation Accuracy: 100.00%\nEpoch 3/5, Validation Accuracy: 100.00%\nEpoch 4/5, Validation Accuracy: 100.00%\nEpoch 5/5, Validation Accuracy: 100.00%\n\nFor ResNet\nEpoch 1/5, Validation Accuracy: 0.00%\nEpoch 2/5, Validation Accuracy: 0.00%\nEpoch 3/5, Validation Accuracy: 0.00%\nEpoch 4/5, Validation Accuracy: 0.00%\nEpoch 5/5, Validation Accuracy: 0.00%","metadata":{}},{"cell_type":"code","source":"# alexnet_model.eval()\n# for epoch in range(num_epoch):\n    \n#     correct = 0\n#     total = 0\n#     for images, labels in spiral_dataloader:\n# #         print(images)\n# #         fig, axes = plt.subplots(1,1)\n# #         axes.imshow(images)\n# #         plt.show()\n# #         plt.imshow(images)\n# #         t_i = normalize_transform(images)\n#         actual_batch_size = images.size(0)\n#         plt.figure(figsize=(15, 15))  # Adjust figure size as needed\n#         for i in range(actual_batch_size):\n#             plt.subplot(4, 8, i + 1)  # Assuming 32 images will be displayed in a 4x8 grid\n# #             plt.imshow(transforms.ToPILImage()(images[i]))\n#             plt.imshow((images[i].permute(1, 2, 0)))# Convert tensor back to PIL Image for plotting\n#             plt.title(f'Label: {class_names[labels[i]]}')\n#             plt.axis('off')\n#         plt.show()\n#         images, labels = images.to('cuda'), labels.to('cuda')\n        \n#         optimiser.zero_grad()\n#         output = alexnet_model(images)\n#         i, predicted = torch.max(output.data, 1)\n        \n# #         print(labels)\n#         for i in range(actual_batch_size):\n#             print(class_names[predicted[i]])\n# #         print(predicted)\n#         correct += predicted.eq(labels).sum().item()\n#         total += labels.size(0)\n    \n#     accuracy = correct/total\n#     print(f\"Epoch {epoch + 1}/{num_epoch}, Validation Accuracy: {accuracy * 100:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2024-04-14T09:52:10.090772Z","iopub.status.idle":"2024-04-14T09:52:10.091114Z","shell.execute_reply.started":"2024-04-14T09:52:10.090951Z","shell.execute_reply":"2024-04-14T09:52:10.090965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# alexnet_model.eval()\n# y_true=[]\n# y_pred=[]\n# with torch.no_grad():\n#     for test_data in test_dataloader:\n#         images, labels = images.to('cuda'), labels.to('cuda')\n#         pred = alexnet_model(images).argmax(dim=1)\n#         for i in range(len(pred)):\n#             y_true.append(labels[i].item())\n#             y_pred.append(pred[i].item())\n# print(len(y_true))\n# print(classification_report(y_true,y_pred,target_names=class_names,digits=4))","metadata":{"execution":{"iopub.status.busy":"2024-04-14T09:52:10.092886Z","iopub.status.idle":"2024-04-14T09:52:10.093616Z","shell.execute_reply.started":"2024-04-14T09:52:10.093327Z","shell.execute_reply":"2024-04-14T09:52:10.093366Z"},"trusted":true},"execution_count":null,"outputs":[]}]}